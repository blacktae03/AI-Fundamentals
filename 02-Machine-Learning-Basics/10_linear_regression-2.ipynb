{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msujeamrK8iO"
      },
      "source": [
        "## 실습 문제: 평균 제곱 오차(MSE) 함수 구현하기\n",
        "\n",
        "**설명**:\n",
        "평균 제곱 오차(Mean Squared Error, MSE)는 회귀(Regression) 문제에서 모델의 성능을 측정하는 대표적인 \\*\\*손실 함수(Loss Function)\\*\\*입니다. 모델이 예측한 값과 실제 정답 값 사이의 차이를 각각 제곱한 뒤, 그 값들의 평균을 내어 계산합니다. 오차를 제곱하기 때문에, 예측이 실제 값에서 많이 벗어날수록 훨씬 더 큰 페널티를 부여하는 특징이 있습니다.\n",
        "\n",
        "이 실습에서는 NumPy를 사용하여 MSE 함수를 직접 구현하고, 주어진 예측값과 실제값 사이의 오차를 계산해 보겠습니다.\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "여기서:\n",
        "\n",
        "  * $n$ : 데이터의 개수\n",
        "  * $y\\_i$ : $i$번째 실제 정답 값\n",
        "  * $\\\\hat{y}\\_i$ : $i$번째 모델의 예측값\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  * 모델의 예측값 `y_pred`와 실제 정답값 `y_true`가 NumPy 배열로 주어집니다.\n",
        "  * `mse` 함수를 구현하여, 두 배열을 입력받아 MSE 값을 계산하도록 만드세요.\n",
        "  * 계산 과정은 다음과 같습니다:\n",
        "    1.  `y_pred`와 `y_true`의 차이를 계산합니다.\n",
        "    2.  차이 배열의 각 원소를 제곱합니다. (`** 2` 또는 `np.square()` 사용)\n",
        "    3.  제곱한 값들의 평균을 계산하여 반환합니다. (`np.mean()` 사용)\n",
        "  * 구현한 함수를 호출하여 주어진 데이터에 대한 MSE 값을 계산하고 출력하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "a = np.array([1,2,7])\n",
        "b = np.array([0,1,0])\n",
        "print(np.mean((a - b) ** 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4l5aN1z8LWKb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def mse(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    실제 값과 예측 값 사이의 평균 제곱 오차(MSE)를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        y_pred (np.ndarray): 모델의 예측 값 배열.\n",
        "        y_true (np.ndarray): 실제 정답 값 배열.\n",
        "\n",
        "    Returns:\n",
        "        float: 계산된 MSE 값.\n",
        "    \"\"\"\n",
        "    return np.mean((y_pred - y_true) ** 2)\n",
        "\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L520_FP7LcaO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.375)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = np.array([3, -0.5, 2, 7])\n",
        "y_pred = np.array([2.5, 0.0, 2, 8])\n",
        "\n",
        "mse(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5EYMWnRUAQ"
      },
      "source": [
        "## 실습 문제: 정규 방정식을 이용한 선형 회귀 해 구하기\n",
        "**설명**: 선형 회귀의 가중치(계수)를 찾는 방법 중 하나는 비용 함수를 최소화하는 해석적 솔루션인 '정규 방정식(Normal Equation)'을 푸는 것입니다. 이 방법은 경사 하강법과 같은 반복적인 최적화 없이 한 번의 계산으로 직접 해를 찾습니다. Scikit-learn의 캘리포니아 주택 가격 데이터셋을 불러온 뒤, NumPy를 사용하여 이 정규 방정식을 직접 구현해 봅니다.\n",
        "\n",
        "$$\\theta = (X^T X)^{-1} X^T y$$\n",
        "\n",
        "**요구사항**:\n",
        "- `solve_normal_equation` 함수 내에서 NumPy를 사용하여 $X$ 행렬에 절편(bias) 항(모든 값이 1인 열)을 추가하여 설계 행렬 `X_b`를 생성하세요. (힌트: `np.c_`와 `np.ones` 사용)\n",
        "- `X_b`와 `y`를 사용하여 정규 방정식 공식 $\\theta = (X_b^T X_b)^{-1} X_b^T y$을 NumPy 코드로 구현하세요. (힌트: 전치는 `.T`, 행렬 곱은 `@`, 역행렬은 `np.linalg.inv` 사용)\n",
        "- 계산된 가중치 벡터 $\\theta$ (첫 번째 요소는 절편, 나머지는 각 특성의 가중치)를 반환하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "arr = np.array([1,2,3,4,5])\n",
        "np.c_[np.ones(())]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PlxBKL7oRWfJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "def solve_normal_equation(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    정규 방정식(Normal Equation)을 사용하여 선형 회귀의\n",
        "    해(가중치 벡터 세타)를 계산합니다.\n",
        "\n",
        "    매개변수:\n",
        "    X (np.ndarray): 입력 특성 행렬 (샘플 수 x 특성 수)\n",
        "    y (np.ndarray): 타겟 벡터 (샘플 수,)\n",
        "\n",
        "    반환값:\n",
        "    np.ndarray: 계산된 가중치 벡터 세타 (절편 포함, (특성 수 + 1,))\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: 1. X 행렬에 절편(bias) 항(1)을 추가하여 X_b를 만듭니다.\n",
        "    # 힌트: np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "\n",
        "    # TODO: 2. 정규 방정식 공식을 구현합니다.\n",
        "    # theta = (X_b.T @ X_b)^-1 @ X_b.T @ y\n",
        "    # 힌트: np.linalg.inv() 함수와 @ 연산자를 사용하세요.\n",
        "    theta = np.linalg.inv((X_b.T @ X_b)) @ X_b.T @ y\n",
        "\n",
        "\n",
        "    return theta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XHPcAbArRX7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터셋 특성 형태: (20640, 8)\n",
            "데이터셋 타겟 형태: (20640,)\n",
            "\n",
            "계산된 세타 (절편 및 가중치):\n",
            "[-3.69419202e+01  4.36693293e-01  9.43577804e-03 -1.07322041e-01\n",
            "  6.45065694e-01 -3.97638940e-06 -3.78654266e-03 -4.21314377e-01\n",
            " -4.34513754e-01]\n",
            "\n",
            "(참고) 세타 벡터의 크기: (9,)\n",
            "첫 번째 값은 절편(bias)이고, 나머지 8개는 각 특성의 가중치입니다.\n"
          ]
        }
      ],
      "source": [
        "# 1. 캘리포니아 주택 가격 데이터셋 로드\n",
        "# return_X_y=True는 (data, target) 튜플을 반환합니다.\n",
        "X, y = datasets.fetch_california_housing(return_X_y=True)\n",
        "\n",
        "print(f\"데이터셋 특성 형태: {X.shape}\")\n",
        "print(f\"데이터셋 타겟 형태: {y.shape}\")\n",
        "\n",
        "# 2. 정규 방정식을 사용하여 해(세타) 계산\n",
        "# 참고: 캘리포니아 데이터셋은 (20640, 8) 크기로,\n",
        "# (9x9) 역행렬 계산은 비교적 빠릅니다.\n",
        "theta = solve_normal_equation(X, y)\n",
        "\n",
        "print(f\"\\n계산된 세타 (절편 및 가중치):\\n{theta}\")\n",
        "\n",
        "# 3. 결과 확인\n",
        "print(f\"\\n(참고) 세타 벡터의 크기: {theta.shape}\")\n",
        "print(f\"첫 번째 값은 절편(bias)이고, 나머지 {X.shape[1]}개는 각 특성의 가중치입니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhaOjc73jI36"
      },
      "source": [
        "## 실습 문제: SVD를 이용한 선형 회귀 가중치($w$) 계산\n",
        "\n",
        "**설명**:\n",
        "선형 회귀 문제는 종종  $Xw = y$  형태의 선형 방정식 시스템으로 표현됩니다. 여기서  $X$ 는 입력 행렬,  $w$ 는 우리가 찾으려는 계수(가중치) 벡터,  $y$ 는 출력 벡터입니다. 선형 회귀의 손실 함수 $L(w) = \\|y - Xw\\|^2$ 를 최소화하는 $w$를 찾는 것이 목표입니다. 이 문제는 $Xw = y$ 라는 선형 방정식 시스템의 최소 제곱 해(least squares solution)를 찾는 것과 같습니다.\n",
        "\n",
        "SVD는 행렬 $X$를 $X = U \\Sigma V^T$ 로 분해하여 이 문제를 안정적으로 풉니다.\n",
        "SVD를 이용하면 손실 함수는 $L(w') = \\|y' - \\Sigma w'\\|^2$ (여기서 $y' = U^T y$, $w' = V^T w$) 라는 간단한 형태로 변환됩니다.\n",
        "\n",
        "이 단순화된 문제의 해는 $w' = \\Sigma^+ y'$ 이며,\n",
        "이를 다시 원래의 $w$로 변환하면 최종 해의 공식 $w = V \\Sigma^+ U^T y$ 를 얻을 수 있습니다.\n",
        "\n",
        "$$w^* = V \\Sigma^+ U^T y$$\n",
        "\n",
        "이 실습의 목표는 `np.linalg.svd`를 사용하여 이 구성 요소들을 직접 계산하고 해 $w$를 구하는 것입니다.\n",
        "\n",
        "**요구사항**:\n",
        "- `solve_svd` 함수 내에서 `np.linalg.svd`를 호출하여 $X$의 SVD 구성 요소 $U$, $s$ (특이값 1차원 배열), $Vh$ ($V^T$)를 얻으세요.\n",
        "- (힌트: `full_matrices=False` 옵션은 $U$의 크기를 `(m, k)`로 축소시켜 메모리와 계산을 효율화합니다.)\n",
        "- $s$ 벡터의 역수(`1.0 / s`)를 계산하고 `np.diag()`를 사용해 $\\Sigma^+$에 해당하는 대각 행렬(`Sigma_plus_diag`)을 만드세요.\n",
        "- $w = V \\Sigma^+ U^T y$ 공식을 NumPy의 행렬 곱셈 연산자(`@`)를 사용하여 구현하세요.\n",
        "- (힌트: `np.linalg.svd`가 반환하는 `Vh`는 $V^T$입니다. 따라서 $V$는 `Vh.T`입니다. $U^T$는 `U.T`입니다.)\n",
        "- 계산된 $w$ 벡터(가중치 및 절편)를 반환하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ih6rD1yOQW9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def solve_svd(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    SVD(특이값 분해)를 사용하여 선형 방정식 시스템 Xw = y의\n",
        "    최소 제곱 해 w (가중치 벡터)를 계산합니다.\n",
        "\n",
        "    이는 손실 함수 L(w) = ||y - Xw||^2 를 최소화하는 w와 같습니다.\n",
        "\n",
        "    매개변수:\n",
        "    X (np.ndarray): 입력 특성 행렬 (m x n) (강의 자료의 X)\n",
        "    y (np.ndarray): 타겟 벡터 (m,) (강의 자료의 y)\n",
        "\n",
        "    반환값:\n",
        "    np.ndarray: 해 벡터 w (n,) (강의 자료의 w)\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: SVD 구성요소를 사용하여 w = V @ Sigma+ @ U.T @ y 를 계산하세요.\n",
        "\n",
        "    # 1. X의 SVD를 계산합니다. (U, s, Vh)\n",
        "    # X = U @ np.diag(S) @ Vh\n",
        "    # 힌트: np.linalg.svd, full_matrices=False\n",
        "    (U, s, Vh) = np.linalg.svd(X, full_matrices=False)\n",
        "\n",
        "    # 2. s의 역수를 대각 행렬로 만듭니다. (Sigma_plus_diag)\n",
        "    # 이것은 Sigma+ (유사 역행렬)에 해당합니다.\n",
        "    # 힌트: np.diag(1.0 / S)\n",
        "    Sigma_plus_diag = np.diag(1.0 / s)\n",
        "\n",
        "    # 3. 해 w = V @ Sigma+ @ U.T @ y 를 계산합니다.\n",
        "    # 힌트: Vh.T, Sigma_plus_diag, U.T, y 와 @ (행렬 곱) 연산자를 사용하세요.\n",
        "    w = Vh.T @ Sigma_plus_diag @ U.T @ y\n",
        "\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KPvo4yRCQYWz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "계산된 해 (m, c): None\n",
            "NumPy lstsq 검증 (m, c): [1.98       1.06666667]\n"
          ]
        }
      ],
      "source": [
        "# --- 예제 데이터 ---\n",
        "# y = 2x + 1 에 약간의 노이즈를 추가한 데이터\n",
        "# Ax = b  ->  [x_data, 1] @ [m, c] = y_data\n",
        "\n",
        "X_data = np.array([0, 1, 2, 3, 4, 5])\n",
        "y_data = np.array([1.1, 2.9, 5.1, 7.0, 9.2, 10.8])\n",
        "\n",
        "# A 행렬 (m x 2)\n",
        "# np.vstack을 사용하여 [X_data]와 [1, 1, ...]을 쌓고 .T로 전치합니다.\n",
        "A = np.vstack([X_data, np.ones(len(X_data))]).T\n",
        "\n",
        "# b 벡터 (m,)\n",
        "b = y_data\n",
        "\n",
        "# SVD를 사용하여 해 x = [m, c] 를 찾습니다.\n",
        "x_solution = solve_svd(A, b)\n",
        "\n",
        "print(f\"계산된 해 (m, c): {x_solution}\")\n",
        "\n",
        "# np.linalg.lstsq를 사용한 검증 (가장 표준적인 방법)\n",
        "x_check, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
        "print(f\"NumPy lstsq 검증 (m, c): {x_check}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGBIly23QkQn"
      },
      "source": [
        "## 실습 문제: StandardScaler 클래스 구현하기\n",
        "\n",
        "**설명**: StandardScaler는 머신러닝에서 매우 중요한 데이터 전처리(preprocessing) 단계입니다. 각 특성(feature, 열)의 평균을 0, 표준편차를 1이 되도록 데이터를 조정하는 **표준화(standardization)** 과정을 수행합니다. 이 실습에서는 NumPy를 사용하여 `StandardScaler` 클래스를 직접 구현합니다. `fit` 메서드는 데이터로부터 평균과 표준편차를 학습하고, `transform` 메서드는 학습된 값을 사용하여 데이터를 실제로 변환합니다.\n",
        "\n",
        "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
        "여기서 $\\mu$는 특성의 평균, $\\sigma$는 특성의 표준편차입니다.\n",
        "\n",
        "**요구사항**:\n",
        "- `StandardScaler` 클래스와 그 안의 `fit`, `transform` 메서드를 완성하세요.\n",
        "- `fit(X)` 메서드:\n",
        "    - 입력 데이터 `X` (`np.ndarray`)의 각 **열(column)**에 대해 평균(`mean`)과 표준편차(`std`)를 계산합니다. (`np.mean`, `np.std`를 `axis=0` 옵션과 함께 사용하세요.)\n",
        "    - 계산된 평균과 표준편차를 각각 `self.mean_`, `self.std_` 인스턴스 변수에 저장하세요.\n",
        "    - **수치 안정성**: 표준편차가 0에 매우 가까우면 (e.g., `self.epsilon` 미만), 나눗셈 오류를 방지하기 위해 해당 값을 **1.0**으로 처리해야 합니다. (`np.where` 사용)\n",
        "- `transform(X)` 메서드:\n",
        "    - `fit` 메서드에서 학습한 `self.mean_`과 `self.std_`를 사용하여 입력 데이터 `X`를 표준화하세요.\n",
        "    - 변환된 데이터를 새로운 `np.ndarray` 객체로 반환하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "85gC12rjQobL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class StandardScaler:\n",
        "    \"\"\"데이터의 각 특성을 표준화하는 클래스\"\"\"\n",
        "    def __init__(self, epsilon: float = 1e-7):\n",
        "        \"\"\"\n",
        "        epsilon: 0으로 나누는 것을 방지하기 위한 작은 값\n",
        "        \"\"\"\n",
        "        self.mean_: np.ndarray | None = None\n",
        "        self.std_: np.ndarray | None = None\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def fit(self, X: np.ndarray):\n",
        "        \"\"\"\n",
        "        입력 데이터 X로부터 각 특성의 평균과 표준편차를 계산하고 저장합니다.\n",
        "        X: (n_samples, n_features) 형태의 2D NumPy 배열\n",
        "        \"\"\"\n",
        "        # TODO: X의 각 열(axis=0)에 대한 평균(mean)을 계산하여 self.mean_에 저장하세요.\n",
        "        self.mean_ = np.mean(X, axis=0)\n",
        "\n",
        "        # TODO: X의 각 열(axis=0)에 대한 표준편차(std)를 계산하세요.\n",
        "        std_dev = np.std(X, axis=0)\n",
        "\n",
        "        # TODO: 수치 안정을 위해, std_dev가 self.epsilon보다 작은 값들을 1.0으로 대체하여 self.std_에 저장하세요.\n",
        "        # (힌트: np.where(std_dev < self.epsilon, 1.0, std_dev) 사용)\n",
        "        self.std_ = np.where(std_dev < self.epsilon, 1.0, std_dev)\n",
        "\n",
        "    def transform(self, X: np.ndarray) -> np.ndarray | None:\n",
        "        \"\"\"\n",
        "        fit()을 통해 학습된 평균과 표준편차를 사용하여 데이터를 변환합니다.\n",
        "        X: (n_samples, n_features) 형태의 2D NumPy 배열\n",
        "        \"\"\"\n",
        "        if self.mean_ is None or self.std_ is None:\n",
        "            raise RuntimeError(\"Scaler has not been fitted yet. Call fit() first.\")\n",
        "\n",
        "        # TODO: (X - self.mean_) / self.std_ 공식을 사용하여 데이터를 변환하고 반환하세요.\n",
        "        # NumPy 브로드캐스팅이 자동으로 행해집니다.\n",
        "        return (X - self.mean_) / self.std_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SJG-zVpQQr3I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data:\n",
            " [[ 1. -1.  2.  5.]\n",
            " [ 2.  0.  0.  5.]\n",
            " [ 0.  1. -1.  5.]]\n",
            "\n",
            "Fitted Mean (self.mean_): [1.         0.         0.33333333 5.        ]\n",
            "\n",
            "Fitted Std Dev (self.std_): [0.81649658 0.81649658 1.24721913 1.        ]\n",
            "\n",
            "--- Verification ---\n",
            "Scaled Data:\n",
            " [[ 0.         -1.22474487  1.33630621  0.        ]\n",
            " [ 1.22474487  0.         -0.26726124  0.        ]\n",
            " [-1.22474487  1.22474487 -1.06904497  0.        ]]\n",
            "\n",
            "Mean of Scaled Data: [0. 0. 0. 0.]\n",
            "Std Dev of Scaled Data: [1. 1. 1. 0.]\n",
            "Is mean close to 0? True\n",
            "Is std dev of non-constant columns close to 1? True\n",
            "Is std dev of constant column 0? True\n"
          ]
        }
      ],
      "source": [
        "# 아래 코드는 StandardScaler 클래스가 모두 구현된 후 정상적으로 작동해야 합니다.\n",
        "# 1. 샘플 데이터 생성 (3개의 데이터, 4개의 특성)\n",
        "# 4번째 특성(열)은 모두 5.0으로, 표준편차가 0인 경우를 테스트합니다.\n",
        "X_train = np.array([\n",
        "    [1.0, -1.0, 2.0, 5.0],\n",
        "    [2.0, 0.0, 0.0, 5.0],\n",
        "    [0.0, 1.0, -1.0, 5.0]\n",
        "])\n",
        "\n",
        "# 2. StandardScaler 객체 생성 및 학습\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 3. 데이터 변환\n",
        "X_scaled = scaler.transform(X_train)\n",
        "\n",
        "# 4. 결과 출력\n",
        "print(\"Original Data:\\n\", X_train)\n",
        "\n",
        "if scaler.mean_ is not None:\n",
        "    print(\"\\nFitted Mean (self.mean_):\", scaler.mean_)\n",
        "else:\n",
        "    print(\"\\nFitted Mean (self.mean_): [TODO]\")\n",
        "\n",
        "if scaler.std_ is not None:\n",
        "    print(\"\\nFitted Std Dev (self.std_):\", scaler.std_)\n",
        "else:\n",
        "    print(\"\\nFitted Std Dev (self.std_): [TODO]\")\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "print(\"Scaled Data:\\n\", X_scaled)\n",
        "\n",
        "# 5. 검증: 변환된 데이터의 평균과 표준편차 확인\n",
        "scaled_mean = np.mean(X_scaled, axis=0)\n",
        "scaled_std = np.std(X_scaled, axis=0)\n",
        "\n",
        "print(\"\\nMean of Scaled Data:\", scaled_mean)\n",
        "print(\"Std Dev of Scaled Data:\", scaled_std)\n",
        "\n",
        "# 평균은 0에 가까워야 함 (상수 열 포함)\n",
        "print(\"Is mean close to 0?\", np.allclose(scaled_mean, 0))\n",
        "# 비-상수 열의 표준편차는 1에 가까워야 함\n",
        "print(\"Is std dev of non-constant columns close to 1?\", np.allclose(scaled_std[:-1], 1))\n",
        "# 상수 열의 표준편차는 0이어야 함 ( (5-5)/1 = 0 이므로)\n",
        "print(\"Is std dev of constant column 0?\", np.allclose(scaled_std[-1], 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8MKpEP_SH18"
      },
      "source": [
        "## 실습 문제: 경사 하강법을 이용한 선형 회귀\n",
        "\n",
        "**설명**:\n",
        "선형 회귀의 가중치(계수 $w$)를 찾는 가장 일반적인 방법 중 하나는 비용 함수(Cost Function, $L(w)$, 보통 MSE)를 최소화하는 것입니다.\n",
        "경사 하강법(Gradient Descent)은 비용 함수의 그래디언트(기울기, $\\nabla L(w)$)를 계산하여, 기울기의 반대 방향으로 $w$ 값을 반복적으로 업데이트하며 최적의 해를 찾아가는 알고리즘입니다. 이 실습에서는 캘리포니아 주택 가격 데이터셋에 배치 경사 하강법(Batch Gradient Descent)을 적용하여 $w$를 직접 계산해 봅니다.\n",
        "(참고: 경사 하강법은 특성들의 스케일에 민감하므로, 코드 스니펫에서 우리가 이전에 구현한 `StandardScaler`를 사용해 데이터 스케일링을 수행합니다.)\n",
        "\n",
        "**그래디언트 공식**:\n",
        "MSE 손실 함수 $L(w) = \\frac{1}{m} \\|X_b w - y\\|^2$ 를 $w$로 미분하면 다음과 같은 그래디언트 공식을 얻습니다.\n",
        "$$\n",
        "\\nabla L(w) = \\frac{2}{m} X_b^T (X_b w - y)\n",
        "$$\n",
        "\n",
        "**요구사항**:\n",
        "- `gradient_descent` 함수를 완성하세요.\n",
        "- $X$ 행렬에 절편(bias) 항(모든 값이 1인 열)을 추가하여 `X_b` 행렬을 생성하세요.\n",
        "- `w` 벡터를 0으로 초기화하세요. 크기는 `X`의 특성 수 + 1 (절편 항) 이어야 합니다.\n",
        "- `n_iterations` 횟수만큼 반복하는 루프를 구현하세요.\n",
        "- 루프 내부에서, 위 그래디언트 공식 $\\nabla L(w)$를 계산하세요. ($m$은 샘플 수)\n",
        "- 계산된 그래디언트와 학습률 `eta` ($\\eta$)를 사용하여 `w` 벡터를 업데이트하세요.\n",
        "- 최종적으로 계산된 `w` 벡터와 `loss_history`를 반환하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sUr72mBhUn-g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "def gradient_descent(X: np.ndarray, y: np.ndarray,\n",
        "                   learning_rate: float,\n",
        "                   n_iterations: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    배치 경사 하강법(Batch Gradient Descent)을 사용하여\n",
        "    선형 회귀의 가중치(세타)를 계산합니다.\n",
        "\n",
        "    매개변수:\n",
        "    X (np.ndarray): 입력 특성 행렬 (샘플 수 x 특성 수)\n",
        "    y (np.ndarray): 타겟 벡터 (샘플 수,)\n",
        "    learning_rate (float): 학습률 (알파)\n",
        "    n_iterations (int): 반복 횟수\n",
        "\n",
        "    반환값:\n",
        "    np.ndarray: 계산된 가중치 벡터 세타 (절편 포함, (특성 수 + 1,))\n",
        "    \"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # 손실을 기록할 리스트 초기화\n",
        "    loss_history = []\n",
        "\n",
        "    # TODO: 1. X 행렬에 절편(bias) 항(1)을 추가하여 X_b를 만듭니다.\n",
        "    # 힌트: np.c_\n",
        "    X_b = np.c_[np.ones((n_samples, 1)), X]\n",
        "\n",
        "    # TODO: 2. 가중치 벡터 w (theta -> w)를 (n_features + 1) 크기의 0 벡터로 초기화합니다.\n",
        "    # 힌트: np.zeros()\n",
        "    w = np.zeros(n_features + 1)\n",
        "\n",
        "    # 3. n_iterations 만큼 반복합니다.\n",
        "    for i in range(n_iterations):\n",
        "\n",
        "        # TODO: 4. 예측값 (h_w)을 계산합니다. (X_b @ w)\n",
        "        predictions = X_b @ w # <-- 학생이 구현\n",
        "\n",
        "        # TODO: 5. 오차 \"벡터\"를 계산합니다. (업데이트용 재료)\n",
        "        errors = predictions - y\n",
        "\n",
        "        # TODO: 6. 현재 손실 \"스칼라\"를 계산하고 기록합니다. (모니터링용)\n",
        "        # 힌트: mse() 함수 사용\n",
        "        current_loss = mse(predictions, y) # <-- 학생이 구현\n",
        "        loss_history.append(current_loss)\n",
        "\n",
        "        # TODO: 7. 그래디언트 \"벡터\"를 계산합니다. (nabla L(w))\n",
        "        # 공식: (1/m) * X_b.T @ errors\n",
        "        gradient = (1/n_samples) * X_b.T @ errors # <-- 학생이 구현\n",
        "\n",
        "        # TODO: 8. w (가중치 벡터)를 업데이트합니다. (실제 학습)\n",
        "        # w_new = w_old - eta * gradient\n",
        "        w = w - learning_rate * gradient # <-- 학생이 구현\n",
        "\n",
        "    return w, loss_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "btpJ3bsUSKyU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 데이터 형태: (20640, 8)\n",
            "스케일링된 데이터의 평균 (0에 가까워야 함): \n",
            "[ 5.50808322e-17  4.40646658e-17  7.71131651e-17 -1.00522519e-16\n",
            " -1.10161664e-17  0.00000000e+00  2.24729795e-15 -8.60362599e-15]\n",
            "스케일링된 데이터의 표준편차 (1에 가까워야 함): \n",
            "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "--- Gradient Descent Results ---\n",
            "Learned Theta (Weights):\n",
            "[ 2.06846887  0.81659877  0.17689017 -0.12729893  0.14127008  0.0166395\n",
            " -0.04392099 -0.48604502 -0.44967077]\n",
            "\n",
            "Final MSE Loss: 0.5531\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- 데이터 준비 ---\n",
        "# 1. 캘리포니아 주택 가격 데이터셋 로드\n",
        "X, y = datasets.fetch_california_housing(return_X_y=True)\n",
        "print(f\"원본 데이터 형태: {X.shape}\")\n",
        "\n",
        "# 2. !! 중요: 우리가 만든 StandardScaler로 특성을 스케일링합니다.\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "print(f\"스케일링된 데이터의 평균 (0에 가까워야 함): \\n{np.mean(X_scaled, axis=0)}\")\n",
        "print(f\"스케일링된 데이터의 표준편차 (1에 가까워야 함): \\n{np.std(X_scaled, axis=0)}\")\n",
        "\n",
        "# --- 하이퍼파라미터 설정 ---\n",
        "learning_rate = 0.01\n",
        "n_iterations = 1000\n",
        "\n",
        "# 4. 경사 하강법 실행\n",
        "theta, loss_history = gradient_descent(X_scaled, y, learning_rate, n_iterations)\n",
        "\n",
        "print(\"--- Gradient Descent Results ---\")\n",
        "print(f\"Learned Theta (Weights):\\n{theta}\")\n",
        "print(f\"\\nFinal MSE Loss: {loss_history[-1]:.4f}\")\n",
        "\n",
        "# 5. 손실(MSE) 감소 그래프 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, n_iterations + 1), loss_history, 'b-')\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Mean Squared Error (MSE Loss)\")\n",
        "plt.title(\"MSE Loss Reduction over Iterations\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn8yPB_4mOxL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
