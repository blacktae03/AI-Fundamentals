{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msujeamrK8iO"
      },
      "source": [
        "## 실습 문제: 평균 제곱 오차(MSE) 함수 구현하기\n",
        "\n",
        "**설명**:\n",
        "평균 제곱 오차(Mean Squared Error, MSE)는 회귀(Regression) 문제에서 모델의 성능을 측정하는 대표적인 \\*\\*손실 함수(Loss Function)\\*\\*입니다. 모델이 예측한 값과 실제 정답 값 사이의 차이를 각각 제곱한 뒤, 그 값들의 평균을 내어 계산합니다. 오차를 제곱하기 때문에, 예측이 실제 값에서 많이 벗어날수록 훨씬 더 큰 페널티를 부여하는 특징이 있습니다.\n",
        "\n",
        "이 실습에서는 NumPy를 사용하여 MSE 함수를 직접 구현하고, 주어진 예측값과 실제값 사이의 오차를 계산해 보겠습니다.\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
        "\n",
        "여기서:\n",
        "\n",
        "  * $n$ : 데이터의 개수\n",
        "  * $y\\_i$ : $i$번째 실제 정답 값\n",
        "  * $\\\\hat{y}\\_i$ : $i$번째 모델의 예측값\n",
        "\n",
        "**요구사항**:\n",
        "\n",
        "  * 모델의 예측값 `y_pred`와 실제 정답값 `y_true`가 NumPy 배열로 주어집니다.\n",
        "  * `mse` 함수를 구현하여, 두 배열을 입력받아 MSE 값을 계산하도록 만드세요.\n",
        "  * 계산 과정은 다음과 같습니다:\n",
        "    1.  `y_pred`와 `y_true`의 차이를 계산합니다.\n",
        "    2.  차이 배열의 각 원소를 제곱합니다. (`** 2` 또는 `np.square()` 사용)\n",
        "    3.  제곱한 값들의 평균을 계산하여 반환합니다. (`np.mean()` 사용)\n",
        "  * 구현한 함수를 호출하여 주어진 데이터에 대한 MSE 값을 계산하고 출력하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4l5aN1z8LWKb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def mse(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
        "    \"\"\"\n",
        "    실제 값과 예측 값 사이의 평균 제곱 오차(MSE)를 계산합니다.\n",
        "\n",
        "    Args:\n",
        "        y_pred (np.ndarray): 모델의 예측 값 배열.\n",
        "        y_true (np.ndarray): 실제 정답 값 배열.\n",
        "\n",
        "    Returns:\n",
        "        float: 계산된 MSE 값.\n",
        "    \"\"\"\n",
        "\n",
        "    return np.mean((y_true - y_pred)**2)\n",
        "\n",
        "    pass\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "L520_FP7LcaO"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float64(0.375)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = np.array([3, -0.5, 2, 7])\n",
        "y_pred = np.array([2.5, 0.0, 2, 8])\n",
        "\n",
        "mse(y_pred, y_true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu5EYMWnRUAQ"
      },
      "source": [
        "## 실습 문제: 정규 방정식을 이용한 선형 회귀 해 구하기\n",
        "**설명**: 선형 회귀의 가중치(계수)를 찾는 방법 중 하나는 비용 함수를 최소화하는 해석적 솔루션인 '정규 방정식(Normal Equation)'을 푸는 것입니다. 이 방법은 경사 하강법과 같은 반복적인 최적화 없이 한 번의 계산으로 직접 해를 찾습니다. Scikit-learn의 캘리포니아 주택 가격 데이터셋을 불러온 뒤, NumPy를 사용하여 이 정규 방정식을 직접 구현해 봅니다.\n",
        "\n",
        "$$\\theta = (X^T X)^{-1} X^T y$$\n",
        "\n",
        "**요구사항**:\n",
        "- `solve_normal_equation` 함수 내에서 NumPy를 사용하여 $X$ 행렬에 절편(bias) 항(모든 값이 1인 열)을 추가하여 설계 행렬 `X_b`를 생성하세요. (힌트: `np.c_`와 `np.ones` 사용)\n",
        "- `X_b`와 `y`를 사용하여 정규 방정식 공식 $\\theta = (X_b^T X_b)^{-1} X_b^T y$을 NumPy 코드로 구현하세요. (힌트: 전치는 `.T`, 행렬 곱은 `@`, 역행렬은 `np.linalg.inv` 사용)\n",
        "- 계산된 가중치 벡터 $\\theta$ (첫 번째 요소는 절편, 나머지는 각 특성의 가중치)를 반환하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PlxBKL7oRWfJ"
      },
      "outputs": [],
      "source": [
        "# 다시 해보기.\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "def solve_normal_equation(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    정규 방정식(Normal Equation)을 사용하여 선형 회귀의\n",
        "    해(가중치 벡터 세타)를 계산합니다.\n",
        "\n",
        "    매개변수:\n",
        "    X (np.ndarray): 입력 특성 행렬 (샘플 수 x 특성 수)\n",
        "    y (np.ndarray): 타겟 벡터 (샘플 수,)\n",
        "\n",
        "    반환값:\n",
        "    np.ndarray: 계산된 가중치 벡터 세타 (절편 포함, (특성 수 + 1,))\n",
        "    \"\"\"\n",
        "\n",
        "    X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
        "    theta = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
        "\n",
        "    return theta\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XHPcAbArRX7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "데이터셋 특성 형태: (20640, 8)\n",
            "데이터셋 타겟 형태: (20640,)\n",
            "\n",
            "계산된 세타 (절편 및 가중치):\n",
            "[-3.69419202e+01  4.36693293e-01  9.43577804e-03 -1.07322041e-01\n",
            "  6.45065694e-01 -3.97638940e-06 -3.78654266e-03 -4.21314377e-01\n",
            " -4.34513754e-01]\n",
            "\n",
            "(참고) 세타 벡터의 크기: (9,)\n",
            "첫 번째 값은 절편(bias)이고, 나머지 8개는 각 특성의 가중치입니다.\n"
          ]
        }
      ],
      "source": [
        "# 1. 캘리포니아 주택 가격 데이터셋 로드\n",
        "# return_X_y=True는 (data, target) 튜플을 반환합니다.\n",
        "X, y = datasets.fetch_california_housing(return_X_y=True)\n",
        "\n",
        "print(f\"데이터셋 특성 형태: {X.shape}\")\n",
        "print(f\"데이터셋 타겟 형태: {y.shape}\")\n",
        "\n",
        "# 2. 정규 방정식을 사용하여 해(세타) 계산\n",
        "# 참고: 캘리포니아 데이터셋은 (20640, 8) 크기로,\n",
        "# (9x9) 역행렬 계산은 비교적 빠릅니다.\n",
        "theta = solve_normal_equation(X, y)\n",
        "\n",
        "print(f\"\\n계산된 세타 (절편 및 가중치):\\n{theta}\")\n",
        "\n",
        "# 3. 결과 확인\n",
        "print(f\"\\n(참고) 세타 벡터의 크기: {theta.shape}\")\n",
        "print(f\"첫 번째 값은 절편(bias)이고, 나머지 {X.shape[1]}개는 각 특성의 가중치입니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhaOjc73jI36"
      },
      "source": [
        "## 실습 문제: SVD를 이용한 선형 회귀 가중치($w$) 계산\n",
        "\n",
        "**설명**:\n",
        "선형 회귀 문제는 종종  $Xw = y$  형태의 선형 방정식 시스템으로 표현됩니다. 여기서  $X$ 는 입력 행렬,  $w$ 는 우리가 찾으려는 계수(가중치) 벡터,  $y$ 는 출력 벡터입니다. 선형 회귀의 손실 함수 $L(w) = \\|y - Xw\\|^2$ 를 최소화하는 $w$를 찾는 것이 목표입니다. 이 문제는 $Xw = y$ 라는 선형 방정식 시스템의 최소 제곱 해(least squares solution)를 찾는 것과 같습니다.\n",
        "\n",
        "SVD는 행렬 $X$를 $X = U \\Sigma V^T$ 로 분해하여 이 문제를 안정적으로 풉니다.\n",
        "SVD를 이용하면 손실 함수는 $L(w') = \\|y' - \\Sigma w'\\|^2$ (여기서 $y' = U^T y$, $w' = V^T w$) 라는 간단한 형태로 변환됩니다.\n",
        "\n",
        "이 단순화된 문제의 해는 $w' = \\Sigma^+ y'$ 이며,\n",
        "이를 다시 원래의 $w$로 변환하면 최종 해의 공식 $w = V \\Sigma^+ U^T y$ 를 얻을 수 있습니다.\n",
        "\n",
        "$$w^* = V \\Sigma^+ U^T y$$\n",
        "\n",
        "이 실습의 목표는 `np.linalg.svd`를 사용하여 이 구성 요소들을 직접 계산하고 해 $w$를 구하는 것입니다.\n",
        "\n",
        "**요구사항**:\n",
        "- `solve_svd` 함수 내에서 `np.linalg.svd`를 호출하여 $X$의 SVD 구성 요소 $U$, $s$ (특이값 1차원 배열), $Vh$ ($V^T$)를 얻으세요.\n",
        "- (힌트: `full_matrices=False` 옵션은 $U$의 크기를 `(m, k)`로 축소시켜 메모리와 계산을 효율화합니다.)\n",
        "- $s$ 벡터의 역수(`1.0 / s`)를 계산하고 `np.diag()`를 사용해 $\\Sigma^+$에 해당하는 대각 행렬(`Sigma_plus_diag`)을 만드세요.\n",
        "- $w = V \\Sigma^+ U^T y$ 공식을 NumPy의 행렬 곱셈 연산자(`@`)를 사용하여 구현하세요.\n",
        "- (힌트: `np.linalg.svd`가 반환하는 `Vh`는 $V^T$입니다. 따라서 $V$는 `Vh.T`입니다. $U^T$는 `U.T`입니다.)\n",
        "- 계산된 $w$ 벡터(가중치 및 절편)를 반환하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Ih6rD1yOQW9d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def solve_svd(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    SVD(특이값 분해)를 사용하여 선형 방정식 시스템 Xw = y의\n",
        "    최소 제곱 해 w (가중치 벡터)를 계산합니다.\n",
        "\n",
        "    이는 손실 함수 L(w) = ||y - Xw||^2 를 최소화하는 w와 같습니다.\n",
        "\n",
        "    매개변수:\n",
        "    X (np.ndarray): 입력 특성 행렬 (m x n) (강의 자료의 X)\n",
        "    y (np.ndarray): 타겟 벡터 (m,) (강의 자료의 y)\n",
        "\n",
        "    반환값:\n",
        "    np.ndarray: 해 벡터 w (n,) (강의 자료의 w)\n",
        "    \"\"\"\n",
        "\n",
        "    U, s, Vh = np.linalg.svd(X, full_matrices=False)\n",
        "    Sigma_plus_diag = np.diag(1.0/s)\n",
        "    \n",
        "    w = Vh.T @ Sigma_plus_diag @ U.T @ y\n",
        "\n",
        "    return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KPvo4yRCQYWz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "계산된 해 (m, c): [1.98       1.06666667]\n",
            "NumPy lstsq 검증 (m, c): [1.98       1.06666667]\n"
          ]
        }
      ],
      "source": [
        "# --- 예제 데이터 ---\n",
        "# y = 2x + 1 에 약간의 노이즈를 추가한 데이터\n",
        "# Ax = b  ->  [x_data, 1] @ [m, c] = y_data\n",
        "\n",
        "X_data = np.array([0, 1, 2, 3, 4, 5])\n",
        "y_data = np.array([1.1, 2.9, 5.1, 7.0, 9.2, 10.8])\n",
        "\n",
        "# A 행렬 (m x 2)\n",
        "# np.vstack을 사용하여 [X_data]와 [1, 1, ...]을 쌓고 .T로 전치합니다.\n",
        "A = np.vstack([X_data, np.ones(len(X_data))]).T\n",
        "\n",
        "# b 벡터 (m,)\n",
        "b = y_data\n",
        "\n",
        "# SVD를 사용하여 해 x = [m, c] 를 찾습니다.\n",
        "x_solution = solve_svd(A, b)\n",
        "\n",
        "print(f\"계산된 해 (m, c): {x_solution}\")\n",
        "\n",
        "# np.linalg.lstsq를 사용한 검증 (가장 표준적인 방법)\n",
        "x_check, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
        "print(f\"NumPy lstsq 검증 (m, c): {x_check}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGBIly23QkQn"
      },
      "source": [
        "## 실습 문제: StandardScaler 클래스 구현하기\n",
        "\n",
        "**설명**: StandardScaler는 머신러닝에서 매우 중요한 데이터 전처리(preprocessing) 단계입니다. 각 특성(feature, 열)의 평균을 0, 표준편차를 1이 되도록 데이터를 조정하는 **표준화(standardization)** 과정을 수행합니다. 이 실습에서는 NumPy를 사용하여 `StandardScaler` 클래스를 직접 구현합니다. `fit` 메서드는 데이터로부터 평균과 표준편차를 학습하고, `transform` 메서드는 학습된 값을 사용하여 데이터를 실제로 변환합니다.\n",
        "\n",
        "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
        "여기서 $\\mu$는 특성의 평균, $\\sigma$는 특성의 표준편차입니다.\n",
        "\n",
        "**요구사항**:\n",
        "- `StandardScaler` 클래스와 그 안의 `fit`, `transform` 메서드를 완성하세요.\n",
        "- `fit(X)` 메서드:\n",
        "    - 입력 데이터 `X` (`np.ndarray`)의 각 **열(column)**에 대해 평균(`mean`)과 표준편차(`std`)를 계산합니다. (`np.mean`, `np.std`를 `axis=0` 옵션과 함께 사용하세요.)\n",
        "    - 계산된 평균과 표준편차를 각각 `self.mean_`, `self.std_` 인스턴스 변수에 저장하세요.\n",
        "    - **수치 안정성**: 표준편차가 0에 매우 가까우면 (e.g., `self.epsilon` 미만), 나눗셈 오류를 방지하기 위해 해당 값을 **1.0**으로 처리해야 합니다. (`np.where` 사용)\n",
        "- `transform(X)` 메서드:\n",
        "    - `fit` 메서드에서 학습한 `self.mean_`과 `self.std_`를 사용하여 입력 데이터 `X`를 표준화하세요.\n",
        "    - 변환된 데이터를 새로운 `np.ndarray` 객체로 반환하세요.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "85gC12rjQobL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "class StandardScaler:\n",
        "    \"\"\"데이터의 각 특성을 표준화하는 클래스\"\"\"\n",
        "    def __init__(self, epsilon: float = 1e-7):\n",
        "        \"\"\"\n",
        "        epsilon: 0으로 나누는 것을 방지하기 위한 작은 값\n",
        "        \"\"\"\n",
        "        self.mean_: np.ndarray | None = None\n",
        "        self.std_: np.ndarray | None = None\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def fit(self, X: np.ndarray):\n",
        "        \"\"\"\n",
        "        입력 데이터 X로부터 각 특성의 평균과 표준편차를 계산하고 저장합니다.\n",
        "        X: (n_samples, n_features) 형태의 2D NumPy 배열\n",
        "        \"\"\"\n",
        "        self.mean_ = np.mean(X, axis=0)\n",
        "        self.std_ = np.std(X, axis=0)\n",
        "        self.std_ = np.where(self.std_ < self.epsilon, 1.0, self.std_) # 0에 가까우면 1로 바꿔야함.\n",
        "        \n",
        "    def transform(self, X: np.ndarray) -> np.ndarray | None:\n",
        "        \"\"\"\n",
        "        fit()을 통해 학습된 평균과 표준편차를 사용하여 데이터를 변환합니다.\n",
        "        X: (n_samples, n_features) 형태의 2D NumPy 배열\n",
        "        \"\"\"\n",
        "        if self.mean_ is None or self.std_ is None:\n",
        "            raise RuntimeError(\"Scaler has not been fitted yet. Call fit() first.\")\n",
        "        \n",
        "        return (X-self.mean_) / self.std_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SJG-zVpQQr3I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Data:\n",
            " [[ 1. -1.  2.  5.]\n",
            " [ 2.  0.  0.  5.]\n",
            " [ 0.  1. -1.  5.]]\n",
            "\n",
            "Fitted Mean (self.mean_): [1.         0.         0.33333333 5.        ]\n",
            "\n",
            "Fitted Std Dev (self.std_): [0.81649658 0.81649658 1.24721913 1.        ]\n",
            "\n",
            "--- Verification ---\n",
            "Scaled Data:\n",
            " [[ 0.         -1.22474487  1.33630621  0.        ]\n",
            " [ 1.22474487  0.         -0.26726124  0.        ]\n",
            " [-1.22474487  1.22474487 -1.06904497  0.        ]]\n",
            "\n",
            "Mean of Scaled Data: [0. 0. 0. 0.]\n",
            "Std Dev of Scaled Data: [1. 1. 1. 0.]\n",
            "Is mean close to 0? True\n",
            "Is std dev of non-constant columns close to 1? True\n",
            "Is std dev of constant column 0? True\n"
          ]
        }
      ],
      "source": [
        "# 아래 코드는 StandardScaler 클래스가 모두 구현된 후 정상적으로 작동해야 합니다.\n",
        "# 1. 샘플 데이터 생성 (3개의 데이터, 4개의 특성)\n",
        "# 4번째 특성(열)은 모두 5.0으로, 표준편차가 0인 경우를 테스트합니다.\n",
        "X_train = np.array([\n",
        "    [1.0, -1.0, 2.0, 5.0],\n",
        "    [2.0, 0.0, 0.0, 5.0],\n",
        "    [0.0, 1.0, -1.0, 5.0]\n",
        "])\n",
        "\n",
        "# 2. StandardScaler 객체 생성 및 학습\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# 3. 데이터 변환\n",
        "X_scaled = scaler.transform(X_train)\n",
        "\n",
        "# 4. 결과 출력\n",
        "print(\"Original Data:\\n\", X_train)\n",
        "\n",
        "if scaler.mean_ is not None:\n",
        "    print(\"\\nFitted Mean (self.mean_):\", scaler.mean_)\n",
        "else:\n",
        "    print(\"\\nFitted Mean (self.mean_): [TODO]\")\n",
        "\n",
        "if scaler.std_ is not None:\n",
        "    print(\"\\nFitted Std Dev (self.std_):\", scaler.std_)\n",
        "else:\n",
        "    print(\"\\nFitted Std Dev (self.std_): [TODO]\")\n",
        "\n",
        "print(\"\\n--- Verification ---\")\n",
        "print(\"Scaled Data:\\n\", X_scaled)\n",
        "\n",
        "# 5. 검증: 변환된 데이터의 평균과 표준편차 확인\n",
        "scaled_mean = np.mean(X_scaled, axis=0)\n",
        "scaled_std = np.std(X_scaled, axis=0)\n",
        "\n",
        "print(\"\\nMean of Scaled Data:\", scaled_mean)\n",
        "print(\"Std Dev of Scaled Data:\", scaled_std)\n",
        "\n",
        "# 평균은 0에 가까워야 함 (상수 열 포함)\n",
        "print(\"Is mean close to 0?\", np.allclose(scaled_mean, 0))\n",
        "# 비-상수 열의 표준편차는 1에 가까워야 함\n",
        "print(\"Is std dev of non-constant columns close to 1?\", np.allclose(scaled_std[:-1], 1))\n",
        "# 상수 열의 표준편차는 0이어야 함 ( (5-5)/1 = 0 이므로)\n",
        "print(\"Is std dev of constant column 0?\", np.allclose(scaled_std[-1], 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8MKpEP_SH18"
      },
      "source": [
        "## 실습 문제: 경사 하강법을 이용한 선형 회귀\n",
        "\n",
        "**설명**:\n",
        "선형 회귀의 가중치(계수 $w$)를 찾는 가장 일반적인 방법 중 하나는 비용 함수(Cost Function, $L(w)$, 보통 MSE)를 최소화하는 것입니다.\n",
        "경사 하강법(Gradient Descent)은 비용 함수의 그래디언트(기울기, $\\nabla L(w)$)를 계산하여, 기울기의 반대 방향으로 $w$ 값을 반복적으로 업데이트하며 최적의 해를 찾아가는 알고리즘입니다. 이 실습에서는 캘리포니아 주택 가격 데이터셋에 배치 경사 하강법(Batch Gradient Descent)을 적용하여 $w$를 직접 계산해 봅니다.\n",
        "(참고: 경사 하강법은 특성들의 스케일에 민감하므로, 코드 스니펫에서 우리가 이전에 구현한 `StandardScaler`를 사용해 데이터 스케일링을 수행합니다.)\n",
        "\n",
        "**그래디언트 공식**:\n",
        "MSE 손실 함수 $L(w) = \\frac{1}{m} \\|X_b w - y\\|^2$ 를 $w$로 미분하면 다음과 같은 그래디언트 공식을 얻습니다.\n",
        "$$\n",
        "\\nabla L(w) = \\frac{2}{m} X_b^T (X_b w - y)\n",
        "$$\n",
        "\n",
        "**요구사항**:\n",
        "- `gradient_descent` 함수를 완성하세요.\n",
        "- $X$ 행렬에 절편(bias) 항(모든 값이 1인 열)을 추가하여 `X_b` 행렬을 생성하세요.\n",
        "- `w` 벡터를 0으로 초기화하세요. 크기는 `X`의 특성 수 + 1 (절편 항) 이어야 합니다.\n",
        "- `n_iterations` 횟수만큼 반복하는 루프를 구현하세요.\n",
        "- 루프 내부에서, 위 그래디언트 공식 $\\nabla L(w)$를 계산하세요. ($m$은 샘플 수)\n",
        "- 계산된 그래디언트와 학습률 `eta` ($\\eta$)를 사용하여 `w` 벡터를 업데이트하세요.\n",
        "- 최종적으로 계산된 `w` 벡터와 `loss_history`를 반환하세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sUr72mBhUn-g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "\n",
        "def gradient_descent(X: np.ndarray, y: np.ndarray,\n",
        "                   learning_rate: float,\n",
        "                   n_iterations: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    배치 경사 하강법(Batch Gradient Descent)을 사용하여\n",
        "    선형 회귀의 가중치(세타)를 계산합니다.\n",
        "\n",
        "    매개변수:\n",
        "    X (np.ndarray): 입력 특성 행렬 (샘플 수 x 특성 수)\n",
        "    y (np.ndarray): 타겟 벡터 (샘플 수,)\n",
        "    learning_rate (float): 학습률 (알파)\n",
        "    n_iterations (int): 반복 횟수\n",
        "\n",
        "    반환값:\n",
        "    np.ndarray: 계산된 가중치 벡터 세타 (절편 포함, (특성 수 + 1,))\n",
        "    \"\"\"\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    X_b = np.c_[np.ones((n_samples, 1)), X]\n",
        "    w = np.zeros((n_features+1))\n",
        "    # 손실을 기록할 리스트 초기화\n",
        "    loss_history = []\n",
        "\n",
        "\n",
        "\n",
        "    # 3. n_iterations 만큼 반복합니다.\n",
        "    for i in range(n_iterations):\n",
        "        grad = 2 * X_b.T @ (X_b @ w - y) / n_samples\n",
        "        w = w - learning_rate * grad\n",
        "        \n",
        "        loss_history.append(mse(X_b @ w, y))\n",
        "        \n",
        "        \n",
        "\n",
        "    return w, loss_history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "btpJ3bsUSKyU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "원본 데이터 형태: (20640, 8)\n",
            "스케일링된 데이터의 평균 (0에 가까워야 함): \n",
            "[ 5.50808322e-17  4.40646658e-17  7.71131651e-17 -1.00522519e-16\n",
            " -1.10161664e-17  0.00000000e+00  2.24729795e-15 -8.60362599e-15]\n",
            "스케일링된 데이터의 표준편차 (1에 가까워야 함): \n",
            "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "--- Gradient Descent Results ---\n",
            "Learned Theta (Weights):\n",
            "[ 2.06855817  0.83900939  0.14736038 -0.23305152  0.25675775  0.00578233\n",
            " -0.04194651 -0.68251625 -0.65183517]\n",
            "\n",
            "Final MSE Loss: 0.5309\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- 데이터 준비 ---\n",
        "# 1. 캘리포니아 주택 가격 데이터셋 로드\n",
        "X, y = datasets.fetch_california_housing(return_X_y=True)\n",
        "print(f\"원본 데이터 형태: {X.shape}\")\n",
        "\n",
        "# 2. !! 중요: 우리가 만든 StandardScaler로 특성을 스케일링합니다.\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X_scaled = scaler.transform(X)\n",
        "\n",
        "print(f\"스케일링된 데이터의 평균 (0에 가까워야 함): \\n{np.mean(X_scaled, axis=0)}\")\n",
        "print(f\"스케일링된 데이터의 표준편차 (1에 가까워야 함): \\n{np.std(X_scaled, axis=0)}\")\n",
        "\n",
        "# --- 하이퍼파라미터 설정 ---\n",
        "learning_rate = 0.01\n",
        "n_iterations = 1000\n",
        "\n",
        "# 4. 경사 하강법 실행\n",
        "theta, loss_history = gradient_descent(X_scaled, y, learning_rate, n_iterations)\n",
        "\n",
        "print(\"--- Gradient Descent Results ---\")\n",
        "print(f\"Learned Theta (Weights):\\n{theta}\")\n",
        "print(f\"\\nFinal MSE Loss: {loss_history[-1]:.4f}\")\n",
        "\n",
        "# 5. 손실(MSE) 감소 그래프 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, n_iterations + 1), loss_history, 'b-')\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Mean Squared Error (MSE Loss)\")\n",
        "plt.title(\"MSE Loss Reduction over Iterations\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn8yPB_4mOxL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
